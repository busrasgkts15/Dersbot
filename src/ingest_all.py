import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings

# --- Yol ayarlarÄ± ---
DATA_ROOT = "../data"
# TEK BÄ°R VERÄ°TABANI DÄ°ZÄ°NÄ° TANIMLIYORUZ
SINGLE_DB_PATH = "../data/chroma_db/all_courses_db"

# --- Embedding modeli ---
embedding_function = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)


def load_all_pdfs_from_root(root_folder):
    """KÃ¶k klasÃ¶r altÄ±ndaki tÃ¼m ders klasÃ¶rlerindeki tÃ¼m PDF dosyalarÄ±nÄ± yÃ¼kler."""
    all_documents = []

    print(f"ğŸ“ PDF'ler taranÄ±yor: {root_folder} altÄ±ndaki tÃ¼m klasÃ¶rler")

    # KÃ¶k klasÃ¶r (../data) altÄ±ndaki tÃ¼m ders klasÃ¶rlerini dolaÅŸ
    for course_folder in os.listdir(root_folder):
        course_path = os.path.join(root_folder, course_folder)

        # Sadece klasÃ¶rleri iÅŸle
        if os.path.isdir(course_path):
            print(f"\nğŸ“‚ Ders KlasÃ¶rÃ¼: {course_folder}")

            # Ders klasÃ¶rÃ¼ndeki tÃ¼m PDF'leri yÃ¼kle
            for file in os.listdir(course_path):
                if file.endswith(".pdf"):
                    pdf_path = os.path.join(course_path, file)
                    print(f"  ğŸ“„ YÃ¼kleniyor: {file}")

                    try:
                        loader = PyPDFLoader(pdf_path)
                        documents = loader.load()

                        # Her parÃ§aya hangi derse ait olduÄŸunu belirten metadata ekleyelim
                        for doc in documents:
                            doc.metadata["source_course"] = (
                                course_folder  # Hangi dersten geldiÄŸi
                            )
                            doc.metadata["source_file"] = file  # Hangi dosyadan geldiÄŸi

                        all_documents.extend(documents)
                    except Exception as e:
                        print(f"  âŒ Hata oluÅŸtu ({file}): {e}")

    return all_documents


def main():
    print("ğŸ“˜ TÃ¼m ders notlarÄ± tek bir veritabanÄ±nda birleÅŸtiriliyor...")

    # 1. TÃ¼m PDF'leri YÃ¼kle
    all_docs = load_all_pdfs_from_root(DATA_ROOT)

    if not all_docs:
        print(
            "âš ï¸ HiÃ§bir PDF dosyasÄ± bulunamadÄ±. LÃ¼tfen '../data' altÄ±ndaki ders klasÃ¶rlerini kontrol edin."
        )
        return

    print(f"\nğŸ“‘ Toplam {len(all_docs)} belge sayfasÄ± yÃ¼klendi.")

    # 2. Metin ParÃ§alarÄ±na AyÄ±r
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    all_chunks = text_splitter.split_documents(all_docs)

    print(f"ğŸ“š Toplam {len(all_chunks)} metin parÃ§asÄ± oluÅŸturuldu.")

    # 3. VeritabanÄ± Dizinini OluÅŸtur
    os.makedirs(SINGLE_DB_PATH, exist_ok=True)

    # 4. Tek Bir Chroma VeritabanÄ± OluÅŸtur ve Kaydet
    print(f"\nğŸ’¾ Chroma veritabanÄ± oluÅŸturuluyor ve kaydediliyor: {SINGLE_DB_PATH}")

    db = Chroma.from_documents(
        all_chunks, embedding_function, persist_directory=SINGLE_DB_PATH
    )
    db.persist()  # Kaydetme iÅŸlemini tamamla

    print(
        f"\nğŸ‰ TÃ¼m ders notlarÄ± tek bir veritabanÄ±na baÅŸarÄ±yla iÅŸlendi ve kaydedildi!"
    )


if __name__ == "__main__":
    main()
